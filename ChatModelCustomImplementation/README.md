# ChatModelCustomImplementation

![ChatModelCustomImplementation](https://raw.githubusercontent.com/rafalbodziony/n8n-workflows-hub/refs/heads/main/ChatModelCustomImplementation/assets/ChatModelCustomImplementation-intr.png)

Workflow demonstrujÄ…cy sposÃ³b obejÅ›cia problemu *â€Request timed outâ€* w wÄ™Åºle **OpenAI Chat Model** w n8n poprzez uÅ¼ycie niestandardowego poÅ‚Ä…czenia z modelem OpenAI w wÄ™Åºle **LangChainCode**.

![ChatModelCustomImplementation-n8n-workflow](https://raw.githubusercontent.com/rafalbodziony/n8n-workflows-hub/refs/heads/main/ChatModelCustomImplementation/assets/zdjecie-problem-w-n8n-brak-odpowiedzi-z-openai.png)

Repozytorium: [n8n-workflows-hub / ChatModelCustomImplementation](https://github.com/rafalbodziony/n8n-workflows-hub/tree/main/ChatModelCustomImplementation)

ArtykuÅ‚ z peÅ‚nym opisem rozwiÄ…zania: [RozwiÄ…zanie problemu Request Timed Out w selektorze modeli n8n](https://kingweb.me/blog/poradniki/rozwiazanie-problemu-request-timed-out-w-selektorze-modeli-n8n)

---

## Opis dziaÅ‚ania

Workflow tworzy wÅ‚asny wÄ™zeÅ‚ poÅ‚Ä…czenia z modelem OpenAI (`LangChainCodeModelConnector`), ktÃ³ry zastÄ™puje standardowy wÄ™zeÅ‚ selektora modeli OpenAI.
DziÄ™ki temu omija ograniczenie czasowe n8n (ok. 180 sekund), umoÅ¼liwiajÄ…c obsÅ‚ugÄ™ dÅ‚uÅ¼szych zapytaÅ„ i peÅ‚ne zwracanie odpowiedzi z API OpenAI.


---

## Struktura workflow

| WÄ™zeÅ‚                                | Typ                  | Opis                                                                               |
| ------------------------------------ | -------------------- | ---------------------------------------------------------------------------------- |
| **When clicking â€˜Execute workflowâ€™** | Manual Trigger       | Uruchamia workflow rÄ™cznie z n8n                                                   |
| **LangChainCodeModelConnector**      | LangChain Code Node  | Tworzy instancjÄ™ `ChatOpenAI` z pakietu `@langchain/openai` i zwraca obiekt LLM    |
| **Basic LLM Chain**                  | LangChain Chain Node | WysyÅ‚a prompt do modelu OpenAI przez niestandardowy konektor i wyÅ›wietla odpowiedÅº |

---

## Dane do uzupeÅ‚nienia

W wÄ™Åºle **LangChainCodeModelConnector**:

```javascript
const OPENAI_API_KEY = ""; // â† wprowadÅº swÃ³j klucz API OpenAI
const MODEL_NAME = "gpt-4.1-mini";
const TEMPERATURE = 0.8;
```

* **OPENAI_API_KEY** â€“ TwÃ³j klucz z [OpenAI Platform](https://platform.openai.com/).
* **MODEL_NAME** â€“ MoÅ¼esz zmieniÄ‡ na dowolny obsÅ‚ugiwany model (np. `gpt-4.1`, `gpt-4o`, `gpt-3.5-turbo`).
* **TEMPERATURE** â€“ Steruje kreatywnoÅ›ciÄ… odpowiedzi (0.0â€“1.0).

---

## DziaÅ‚anie

1. Uruchom workflow rÄ™cznie w n8n.
2. WÄ™zeÅ‚ **LangChainCodeModelConnector** inicjalizuje poÅ‚Ä…czenie z modelem OpenAI.
3. WÄ™zeÅ‚ **Basic LLM Chain** wysyÅ‚a przykÅ‚adowy prompt â€Ile to 2+5?â€ i odbiera odpowiedÅº.
4. Wynik wyÅ›wietla siÄ™ w oknie podglÄ…du wÄ™zÅ‚a.

---

## Zastosowanie

* Eliminacja bÅ‚Ä™du `Request timed out` w selektorze modeli OpenAI.
* MoÅ¼liwoÅ›Ä‡ peÅ‚nej kontroli parametrÃ³w poÅ‚Ä…czenia (`temperature`, `model`, `maxTokens` itp.).
* UÅ¼ycie w bardziej zÅ‚oÅ¼onych procesach: ranking, zapytania do baz wektorowych, generowanie treÅ›ci.

---

## Linki

* [ArtykuÅ‚ opisujÄ…cy rozwiÄ…zanie](https://kingweb.me/blog/poradniki/rozwiazanie-problemu-request-timed-out-w-selektorze-modeli-n8n)
* [Repozytorium z workflow](https://github.com/rafalbodziony/n8n-workflows-hub/tree/main/ChatModelCustomImplementation)

---

Aby uruchomiÄ‡:

1. Zaimportuj plik `ChatModelCustomImplementation.json` do n8n.
2. OtwÃ³rz wÄ™zeÅ‚ **LangChainCodeModelConnector**.
3. Wklej swÃ³j **OPENAI_API_KEY**.
4. Uruchom workflow przyciskiem *Execute workflow*.

--- 
#### ğŸ“œ Licencja

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)


Copyright (c) 2025 RafaÅ‚ Bodziony @ kingweb.pl, kingweb.me.

